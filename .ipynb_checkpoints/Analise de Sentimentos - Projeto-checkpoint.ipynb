{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de Sentimentos\n",
    "    Resumo:\n",
    "    Link da documentação:\n",
    "    Link do repositório:\n",
    "    \n",
    "Integrantes: <br>\n",
    "    Bruno Sampaio <br>\n",
    "    Eric Saboia <br>\n",
    "    Gabriel Puente <br>\n",
    "    Israel Junior <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importações para o projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importação dos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo: DataSet_Bolsonaro.xlsx\t-  Folha: DS-PN-CL\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_excel('dados.xlsx', sheet_name='DS-PN-CL', encoding='utf-8')\n",
    "frases = tweets['Text'].str.lower()\n",
    "print(\"Arquivo: DataSet_Bolsonaro.xlsx\t-  Folha: DS-PN-CL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    resultado = modelo.fit(treino_dados, treino_marcacoes)\n",
    "    fit_and_predict_score = str(modelo.score(treino_dados, treino_marcacoes))\n",
    "    print(\"ETAPA TREINO \"+ nome + \"- Acurácia: \" + fit_and_predict_score)\n",
    "    print(\"Devio Padrão: \" + str(np.std(treino_dados,  dtype=np.float64)))\n",
    "    print(\"==============================================================\")\n",
    "    return fit_and_predict_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valida_dados(modelo, validacao_dados, validacao_marcacoes):\n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "    metricas(resultado,validacao_marcacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(resultado,validacao_marcacoes):\n",
    "    \n",
    "    #Apresentação do report contendo precision, recall and F-measures\n",
    "    if len(set(resultado)) > 2:\n",
    "        target_names = ['negativo', 'positivo', 'neutro']\n",
    "        #os valores acima estão na ordem correta\n",
    "        print(classification_report(validacao_marcacoes, resultado, target_names=target_names))\n",
    "    else:\n",
    "        print(\"Classification Report\\n\")\n",
    "        target_names = ['negativo', 'positivo']\n",
    "        #os valores acima estão na ordem correta\n",
    "        print(classification_report(validacao_marcacoes, resultado, target_names=target_names))       \n",
    "\n",
    "        #Apresentação dos true positive, false positive, true negative e false negative\n",
    "        tn, fp, fn, tp = confusion_matrix(validacao_marcacoes, resultado).ravel() \n",
    "        msg = \"True Positive: {0} \\nFalse Positive: {1}\\nTrue Negative: {2}\\nFalse Negative: {3}\".format(str(tn),str(fp),str(fn),str(tp))\n",
    "        print(msg+\"\\n\")\n",
    "\n",
    "        matrix_confusao(validacao_marcacoes, resultado,target_names)\n",
    "\n",
    "        print(\"Metrics\\n\")\n",
    "        \n",
    "        print(\"Precision: \" + str(precision_score(validacao_marcacoes, resultado))) \n",
    "        print(\"Recall: \" + str(recall_score(validacao_marcacoes, resultado))) \n",
    "        #Cria estatistica dos resultados.\n",
    "        \n",
    "\n",
    "    print(\"F-score: \" + str(f1_score(validacao_marcacoes, resultado)))\n",
    "    taxa_de_acerto_base = max(Counter(validacao_marcacoes).values()) * 100 / len(validacao_marcacoes)\n",
    "    print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "    #Apresentação da accuracy e resultado final\n",
    "    #print(\"Acurácia: \" + str(accuracy_score(validacao_marcacoes, resultado)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_confusao(validacao_marcacoes, resultado, target_names):\n",
    "    cnf_matrix = confusion_matrix(validacao_marcacoes, resultado)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_modelos(treino_dados, treino_marcacoes):\n",
    "    resultados = {}\n",
    "    '''\n",
    "    # OneVsRestClassifier - LinearSVC\n",
    "    modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "    \n",
    "    # OneVsOneClassifier\n",
    "    modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "    resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "    '''\n",
    "    # MultinomialNB\n",
    "    modeloMultinomial = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "    resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoMultinomial] = modeloMultinomial\n",
    "    \n",
    "    # AdaBoostClassifier\n",
    "    modeloAdaBoost = AdaBoostClassifier(random_state=0)\n",
    "    resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "    \n",
    "    modeloDecisionTree = DecisionTreeClassifier(random_state=0)\n",
    "    resultadoDecisionTree = fit_and_predict(\"DecisionTree\", modeloDecisionTree, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoDecisionTree] = modeloDecisionTree\n",
    "\n",
    "    modeloRandomForest = RandomForestClassifier(random_state=0)\n",
    "    resultadoRandomForest = fit_and_predict(\"RandomForest\", modeloRandomForest, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoRandomForest] = modeloRandomForest\n",
    "\n",
    "    modeloLogisticRegression = LogisticRegression(random_state = 0)\n",
    "    resultadoLogisticRegression = fit_and_predict(\"LogisticRegression\", modeloLogisticRegression, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoLogisticRegression] = modeloLogisticRegression\n",
    "\n",
    "    modeloSVC = SVC(random_state = 0)\n",
    "    resultadoSVC = fit_and_predict(\"SVC RBF Kernel\", modeloSVC, treino_dados, treino_marcacoes)\n",
    "    resultados[resultadoSVC] = modeloSVC\n",
    "    \n",
    "\n",
    "    #Verifica qual modelo teve a melhor perfomance\n",
    "    maximo = max(resultados)\n",
    "    return resultados[maximo], resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_dados(tweets, frases):\n",
    "    marcas = tweets['Sentimento']\n",
    "\n",
    "    X = frases\n",
    "    Y = marcas.values\n",
    "    \n",
    "    #Divisão de dados para treino e validação.\n",
    "    porcentagem_de_treino = 0.8\n",
    "    \n",
    "    tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "    tamanho_de_validacao = len(Y) - tamanho_de_treino\n",
    "    \n",
    "    treino_dados = X[0:tamanho_de_treino]\n",
    "    treino_marcacoes = Y[0:tamanho_de_treino]\n",
    "    \n",
    "    validacao_dados = X[tamanho_de_treino:]\n",
    "    validacao_marcacoes = Y[tamanho_de_treino:]\n",
    "    \n",
    "    #treino_dados = pd.get_dummies(treino_dados).values\n",
    "    #validacao_dados = pd.get_dummies(validacao_dados).values\n",
    "    \n",
    "\n",
    "    return treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes, tamanho_de_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento(dados):\n",
    "    \n",
    "    textosTokenizados = [nltk.tokenize.word_tokenize(frase) for frase in dados]\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer();       \n",
    "    \n",
    "    dicionario = set()\n",
    "    for lista in textosTokenizados:\n",
    "        validas = [stemmer.stem(palavra) for palavra in lista if palavra not in stopwords and len(palavra) > 2]\n",
    "        dicionario.update(validas)\n",
    "    \n",
    "\n",
    "    totalDePalavras = len(dicionario)\n",
    "    \n",
    "    tuplas = zip(dicionario, range(totalDePalavras))\n",
    "    tradutor = {palavra: indice for palavra, indice in tuplas}\n",
    "\n",
    "    vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosTokenizados]\n",
    "    #print(tradutor)\n",
    "    return vetoresDeTexto, dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_validacao(dados, dicionario):\n",
    "    #aplica a tokenização\n",
    "    textosTokenizados = [nltk.tokenize.word_tokenize(frase) for frase in dados]\n",
    "\n",
    "    #aplica as stop words, isto é, remove os pronomes e etc.\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    #aplica steem, isto é, deixa a palavra na forma raiz\n",
    "    stemmer = nltk.stem.RSLPStemmer();\n",
    "    \n",
    "    totalDePalavras = len(dicionario)\n",
    "    #print(totalDePalavras)\n",
    "    #print(dicionario)\n",
    "    tuplas = zip(dicionario, range(totalDePalavras))\n",
    "    tradutor = {palavra: indice for palavra, indice in tuplas}\n",
    "\n",
    "    vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosTokenizados]\n",
    "\n",
    "    return vetoresDeTexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_antigo(tweets, frases):\n",
    "    X = frases\n",
    "    Y = tweets['Sentimento']\n",
    "    \n",
    "    #Divisão de dados para treino, teste e validação.\n",
    "    porcentagem_de_treino = 0.8\n",
    "    \n",
    "    tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "    tamanho_de_validacao = len(Y) - tamanho_de_treino\n",
    "    \n",
    "    treino_dados = X[0:tamanho_de_treino]\n",
    "    treino_marcacoes = Y[0:tamanho_de_treino]\n",
    "    \n",
    "    validacao_dados = X[tamanho_de_treino:]\n",
    "    validacao_marcacoes = Y[tamanho_de_treino:]\n",
    "\n",
    "    #aplica a tokenização e cria a back of words\n",
    "    textosQuebrados = [nltk.tokenize.word_tokenize(frase) for frase in X[0:tamanho_de_treino]]\n",
    "\n",
    "    #aplica as stop words, isto é, remove os pronomes e etc.\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    #aplica steem, isto é, deixa a palavra na forma raiz\n",
    "    stemmer = nltk.stem.RSLPStemmer();\n",
    "    \n",
    "    dicionario = set()\n",
    "    for lista in textosQuebrados:\n",
    "        validas = [stemmer.stem(palavra) for palavra in lista if palavra not in stopwords and len(palavra) > 2]\n",
    "        dicionario.update(validas)\n",
    "    #print(dicionario)\n",
    "\n",
    "\n",
    "    totalDePalavras = len(dicionario)\n",
    "    #print(totalDePalavras)\n",
    "    #print(dicionario)\n",
    "    tuplas = zip(dicionario, range(totalDePalavras))\n",
    "    tradutor = {palavra: indice for palavra, indice in tuplas}\n",
    "\n",
    "\n",
    "    treino_dados = vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosQuebrados]\n",
    "    \n",
    "    return treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_holdout(tweets, frases):\n",
    "    print(\"\\n***************************\")\n",
    "    print(\"PROCESSAMENTO - HOLDOUT\")\n",
    "    print(\"***************************\")\n",
    "    treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes, tamanho_de_treino = divide_dados(tweets, frases)\n",
    "\n",
    "    treino_dados, dicionario = pre_processamento(treino_dados)\n",
    "    validacao_dados = pre_processamento_validacao(validacao_dados, dicionario)\n",
    "\n",
    "    #Encontrando o modelo vencedor\n",
    "    vencedor,resultados = cria_modelos(treino_dados, treino_marcacoes)\n",
    "    print(\"Modelo vencedor: \" + str(vencedor)+\"\\n\")\n",
    "\n",
    "    #Validando o modelo com novos dados\n",
    "    vencedor.fit(treino_dados, treino_marcacoes)\n",
    "    valida_dados(vencedor, validacao_dados, validacao_marcacoes) \n",
    "\n",
    "    dados = np.concatenate((treino_dados, validacao_dados), axis=0)\n",
    "    marcacao = np.concatenate((treino_marcacoes, validacao_marcacoes), axis=0)\n",
    "    return dados, marcacao, resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_kfold(dados, marcacao):\n",
    "    contador = 1\n",
    "    print(\"\\n***************************\")\n",
    "    print(\"PROCESSAMENTO - KFOLD\")\n",
    "    print(\"***************************\\n\")\n",
    "    random_split = StratifiedShuffleSplit(marcacao, test_size=.25, random_state=0)\n",
    "    for train_index, test_index in random_split.split(dados, marcacao):\n",
    "        treino_dados, treino_marcacoes = dados[train_index], dados[test_index]\n",
    "        validacao_dados, validacao_marcacoes = marcacao[train_index], marcacao[test_index]\n",
    "        print(\"GRUPO: \"+ str(contador))\n",
    "        \n",
    "        print(len(treino_dados))\n",
    "        print(len(treino_marcacoes))\n",
    "        print(len(validacao_dados))\n",
    "        print(len(validacao_marcacoes))\n",
    "\n",
    "        #Encontrando o modelo vencedor\n",
    "        vencedor, resultados = cria_modelos(treino_dados, treino_marcacoes)\n",
    "        print(\"Modelo vencedor: \" + str(vencedor)+\"\\n\")\n",
    "\n",
    "        #Validando o modelo com novos dados\n",
    "        vencedor.fit(treino_dados, treino_marcacoes)\n",
    "        valida_dados(vencedor, validacao_dados, validacao_marcacoes) \n",
    "\n",
    "        contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_kfold_2(dados, marcacao, resultados):\n",
    "    print(\"\\n***************************\\n\")\n",
    "    print(\"PROCESSAMENTO - KFOLD\")\n",
    "    print(\"\\n***************************\\n\")\n",
    "    contador = 1\n",
    "    k = 5\n",
    "    for iterator in resultados:\n",
    "        print(\"GRUPO: \"+ str(contador))\n",
    "        print(\"Nome: \"+ str(resultados[iterator]))        \n",
    "        scores = cross_val_score(resultados[iterator], dados, marcacao, cv=k, scoring='f1')\n",
    "        taxa_de_acerto = np.mean(scores)\n",
    "        print(\"Taxa de acerto: \" + str(taxa_de_acerto))\n",
    "        contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar(tweets, frases):\n",
    "    #Descomente caso seja primeira vez de execução. Funcionalidaeds de processamento\n",
    "    #nltk.download('stopwords')\n",
    "    #nltk.download('rslp')\n",
    "    #nltk.download('punkt')\n",
    "\n",
    "    dados, marcacao, resultados = processamento_holdout(tweets, frases)\n",
    "    #processamento_kfold(dados, marcacao)\n",
    "    processamento_kfold_2(dados, marcacao, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************\n",
      "PROCESSAMENTO - HOLDOUT\n",
      "***************************\n",
      "ETAPA TREINO MultinomialNB- Acurácia: 0.9625984251968503\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n",
      "ETAPA TREINO AdaBoostClassifier- Acurácia: 0.8818897637795275\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n",
      "ETAPA TREINO DecisionTree- Acurácia: 1.0\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA TREINO RandomForest- Acurácia: 0.9862204724409449\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA TREINO LogisticRegression- Acurácia: 0.984251968503937\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA TREINO SVC RBF Kernel- Acurácia: 0.6437007874015748\n",
      "Devio Padrão: 0.08995635977443797\n",
      "==============================================================\n",
      "Modelo vencedor: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.00      0.00      0.00         0\n",
      "    positivo       1.00      0.58      0.73       128\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       128\n",
      "   macro avg       0.50      0.29      0.37       128\n",
      "weighted avg       1.00      0.58      0.73       128\n",
      "\n",
      "True Positive: 0 \n",
      "False Positive: 0\n",
      "True Negative: 54\n",
      "False Negative: 74\n",
      "\n",
      "Metrics\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.578125\n",
      "F-score: 0.7326732673267327\n",
      "Taxa de acerto base: 100.000000\n",
      "\n",
      "***************************\n",
      "\n",
      "PROCESSAMENTO - KFOLD\n",
      "\n",
      "***************************\n",
      "\n",
      "GRUPO: 1\n",
      "Nome: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 0.7626733193277311\n",
      "GRUPO: 2\n",
      "Nome: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=0)\n",
      "Taxa de acerto: 0.671340559414192\n",
      "GRUPO: 3\n",
      "Nome: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "Taxa de acerto: 0.7232115512654238\n",
      "GRUPO: 4\n",
      "Nome: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "Taxa de acerto: 0.7407835820895522\n",
      "GRUPO: 5\n",
      "Nome: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Taxa de acerto: 0.7709666746977918\n",
      "GRUPO: 6\n",
      "Nome: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processar(tweets, frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
