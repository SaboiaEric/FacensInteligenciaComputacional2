{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de Sentimentos\n",
    "    Resumo:\n",
    "    Link da documentação:\n",
    "    Link do repositório:\n",
    "    \n",
    "Integrantes: <br>\n",
    "    Bruno Sampaio <br>\n",
    "    Eric Saboia <br>\n",
    "    Gabriel Puente <br>\n",
    "    Israel Junior <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importações para o projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Importações dos dados e Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_excel('dados.xlsx', sheet_name='DS-PN-ID', encoding='utf-8')\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Técnicas Genéricas de Tratamento de dados\n",
    "    Funções simples para tratar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacao_minuscula(texto):\n",
    "    texto = texto.str.lower()\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_atributos_rotulos(dados):\n",
    "    atributos = tweets.Text\n",
    "    rotulos = tweets.Sentimento\n",
    "    return atributos, rotulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Técnicas de Processamento de Linguagem Natural (PLN)\n",
    "    Funções de aplicações das técnicas de PLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento(dados):\n",
    "    textosTokenizados = [nltk.tokenize.word_tokenize(frase) for frase in dados]\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer();       \n",
    "    \n",
    "    dicionario = set()\n",
    "    for lista in textosTokenizados:\n",
    "        validas = [stemmer.stem(palavra) for palavra in lista if palavra not in stopwords and len(palavra) > 2]\n",
    "        dicionario.update(validas)\n",
    "    \n",
    "\n",
    "    totalDePalavras = len(dicionario)\n",
    "    \n",
    "    tuplas = zip(dicionario, range(totalDePalavras))\n",
    "    tradutor = {palavra: indice for palavra, indice in tuplas}\n",
    "\n",
    "    vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosTokenizados]\n",
    "    #print(tradutor)\n",
    "    return vetoresDeTexto, dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_validacao(dados, dicionario):\n",
    "    #aplica a tokenização\n",
    "    textosTokenizados = [nltk.tokenize.word_tokenize(frase) for frase in dados]\n",
    "\n",
    "    #aplica as stop words, isto é, remove os pronomes e etc.\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    #aplica steem, isto é, deixa a palavra na forma raiz\n",
    "    stemmer = nltk.stem.RSLPStemmer();\n",
    "    \n",
    "    totalDePalavras = len(dicionario)\n",
    "    #print(totalDePalavras)\n",
    "    #print(dicionario)\n",
    "    tuplas = zip(dicionario, range(totalDePalavras))\n",
    "    tradutor = {palavra: indice for palavra, indice in tuplas}\n",
    "\n",
    "    vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosTokenizados]\n",
    "\n",
    "    return vetoresDeTexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  Válidações e métodos utilizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.  Holdout\n",
    "    Divisao dos dados: 70 treino /30 teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdoutValidacao(atributos, rotulos):\n",
    "    return train_test_split(atributos, rotulos, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.  Cross-Validation K-Fold\n",
    "    K = 5 (será utilizada técnicas de otimizações para encontrar o melhor K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.  Cross-Validation K-Fold (Estrátificado)\n",
    "    K = 5 (será utilizada técnicas de otimizações para encontrar o melhor K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  Modelos e algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  Processamento\n",
    "    Os dados coletados estão na váriavel 'tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributo, rotulos = separa_atributos_rotulos(tweets)\n",
    "atributo = transformacao_minuscula(atributos)\n",
    "treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes = holdoutValidacao(atributo, rotulos)\n",
    "treino_dados, dicionario = pre_processamento(treino_dados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
